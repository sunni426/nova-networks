{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Download BBBC036 Dataset**\n",
    "https://bbbc.broadinstitute.org/BBBC036\n",
    "- 693 Mechanisms of Action (MoA) labels\n",
    "- 5 channels (ERSyto, ERSytoBleed, Hoechst, Mito, Ph_golgi)\n",
    "    - Per channel:\n",
    "        -  384 wells (a01, a02, a03, ...)\n",
    "        - 6 FoV (s1, s2, ..., s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "- Run **_download_bbbc036.sh_**\n",
    "    - Customizable parameters: \"PARENT_DIR\" | \"PLATE_NUMBERS\" | \"-P 16\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "- Unzip .zip files\n",
    "    - Customizable parameters: \"PARENT_DIR\" | \"ZIP_DIR\" | \"UNZIP_DIR\"\n",
    "- Example:\n",
    "```plaintext\n",
    "        csv_unzip\n",
    "        ├── 24279-ERSyto\n",
    "        │   ├── cdp2bioactives_a01_s1_*.tif\n",
    "        │   ├── cdp2bioactives_a01_s2_*.tif\n",
    "        │   ├── cdp2bioactives_a01_s3_*.tif\n",
    "        │   └── ...\n",
    "        ├── 24279-ERSytoBleed\n",
    "        ├── 24279-Hoechst\n",
    "        ├── 24279-Mito\n",
    "        ├── 24279-Ph_golgi\n",
    "        ├── ...\n",
    "        └── 24279-profiles.csv\n",
    "        └── ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "PARENT_DIR = \"/projectnb/btec-design3/novanetworks/kaggle_HPA/2021/data/bbbc036/raw/\"\n",
    "ZIP_DIR = \"/projectnb/btec-design3/novanetworks/kaggle_HPA/2021/data/bbbc036/raw/csv_zip\"\n",
    "\n",
    "# Define the output directory where ZIP contents will be extracted\n",
    "UNZIP_DIR = os.path.join(PARENT_DIR, \"csv_unzip\")\n",
    "os.makedirs(UNZIP_DIR, exist_ok=True)\n",
    "\n",
    "# List files in the zip directory\n",
    "files = os.listdir(ZIP_DIR)\n",
    "zip_files = [file for file in files if file.endswith(\".zip\")]\n",
    "csv_files = [file for file in files if file.endswith(\".csv\")]\n",
    "\n",
    "batch_size = 5\n",
    "zip_file_batches = [zip_files[i:i + batch_size] for i in range(0, len(zip_files), batch_size)]\n",
    "\n",
    "# Unzip each batch of ZIP files\n",
    "for batch_index, zip_batch in enumerate(tqdm(zip_file_batches, desc=\"Processing batches\"), start=1):\n",
    "    for zip_file in tqdm(zip_batch, desc=f\"Unzipping batch {batch_index}\", leave=False):\n",
    "        zip_file_path = os.path.join(ZIP_DIR, zip_file)\n",
    "        \n",
    "        try:\n",
    "            subprocess.run([\"unzip\", zip_file_path, \"-d\", UNZIP_DIR], check=True)\n",
    "            # print(f\"Extracted {zip_file} to {UNZIP_DIR}\")\n",
    "            # Delete the ZIP file after successful extraction to free up the space\n",
    "            os.remove(zip_file_path)\n",
    "            # print(f\"Deleted {zip_file} after extraction\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to extract {zip_file}: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "    # Copy all CSV files to the output directory after each batch\n",
    "    for csv_file in tqdm(csv_files, desc=\"Copying CSV files\", leave=False):\n",
    "        src_csv_path = os.path.join(ZIP_DIR, csv_file)\n",
    "        dst_csv_path = os.path.join(UNZIP_DIR, csv_file)\n",
    "        shutil.copy(src_csv_path, dst_csv_path)\n",
    "        # print(f\"Copied {csv_file} to {UNZIP_DIR}\")\n",
    "\n",
    "    if batch_index < len(zip_file_batches):\n",
    "        print(f\"Batch {batch_index} completed. Proceeding to the next batch.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Process CSV Files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "- Use **_{plate}-profiles.csv_** file for each plate and **_BBBC036_v1_DatasetGroundTruth.csv_** to make a new csv file for model training \n",
    "    - Customizable parameters: \"PROFILE_DIR\" | \"GT_DIR\"\n",
    "- Purpose:\n",
    "    - Match images with their corresponding BROAD sample numbers and MoA labels\n",
    "    - Convert ground truth labels into formats interpretable by the model\n",
    "- Output:\n",
    "    - **_train_bbbc.csv_** <font color=\"orange\">&rarr; Place this file into \"nova-networks/Nova-Classifier/dataloaders/split\"</font>\n",
    "\n",
    "### Step 2\n",
    "- Use **_train_bbbc.csv_** and convert MoA labels to class numbers, such as class 0, 1, ..., 692\n",
    "- Output:\n",
    "    - **_bbbc_numclass.csv_**\n",
    "\n",
    "### Step 3\n",
    "- Use **_bbbc_numclass.csv_** and expand the each row to contain Metadata_Plate, Metadata_Well, Metadata_broad_sample, and 693 classes columns\n",
    "- If the label is presented in the image, class columns will be labeled as 1, otherwise 0\n",
    "- Output:\n",
    "    - **_transformed_file.csv_**\n",
    " \n",
    " ### Step 4\n",
    " - Use **_transformed_file.csv_** to check whether the cropped image folder have the image listed in the csv\n",
    " - This also checks whether this image ID (Metadata_Plate + Metadata_Well) have 10 individual cropped cell\n",
    " - If it meets both criteria, the row corresponding to the image ID will be saved, otherwise removed from the csv\n",
    " - Output:\n",
    "    - **_bbbc2_rename_10cell.csv_** for model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to \"{plate}-profiles.csv\" files\n",
    "PROFILE_DIR = '/projectnb/btec-design3/novanetworks/kaggle_HPA/2021/data/bbbc036/raw/csv_unzip'\n",
    "\n",
    "# Path to the \"BBBC036_v1_DatasetGroundTruth.csv\" file in the metadata folder\n",
    "GT_DIR = '/projectnb/btec-design3/novanetworks/nova-networks/preprocessing/BBBC036/metadata/BBBC036_v1_DatasetGroundTruth.csv'\n",
    "\n",
    "\n",
    "ground_truth = pd.read_csv(GT_DIR)\n",
    "moa_mapping = ground_truth.set_index('Metadata_broad_sample')['Metadata_moa'].to_dict()\n",
    "\n",
    "\n",
    "# Create a DataFrame to store filtered & combined data\n",
    "combined_data = pd.DataFrame(columns=[\"Metadata_Plate\",\"Metadata_Well\", \"Metadata_broad_sample\", \"Metadata_moa\"])\n",
    "\n",
    "for file in os.listdir(PROFILE_DIR):\n",
    "    if file.endswith(\"-profiles.csv\"):\n",
    "        profile_data = pd.read_csv(os.path.join(PROFILE_DIR, file))\n",
    "\n",
    "        profile_data['Metadata_moa'] = profile_data['Metadata_broad_sample'].map(moa_mapping)\n",
    "        profile_data.dropna(subset=['Metadata_moa'], inplace=True)\n",
    "\n",
    "        combined_data = pd.concat([combined_data, profile_data[[\"Metadata_Plate\",\"Metadata_Well\", \"Metadata_broad_sample\", \"Metadata_moa\"]]], ignore_index=True)\n",
    "\n",
    "\n",
    "combined_data.to_csv(os.path.join(PROFILE_DIR, \"train_bbbc.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'dataloaders/split/train_bbbc.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "all_classes = df.iloc[:, 3].str.split('|').explode()\n",
    "unique_classes = all_classes.unique()\n",
    "class_to_number = {class_name: i for i, class_name in enumerate(unique_classes)}\n",
    "\n",
    "print(len(class_to_number)) #693 classes\n",
    "df.iloc[:, 3] = df.iloc[:, 3].str.split('|').apply(lambda classes: '|'.join(str(class_to_number[c]) for c in classes))\n",
    "\n",
    "df.to_csv('bbbc_numclass.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the original CSV file\n",
    "original_df = pd.read_csv('bbbc_numclass.csv')\n",
    "\n",
    "# Split the classes in the fourth column and create a list of unique classes\n",
    "class_labels = '|'.join(original_df.iloc[:, 3]).split('|')\n",
    "classes = set(class_labels)\n",
    "\n",
    "# Convert class labels to integers\n",
    "class_labels_int = [int(label) for label in class_labels]\n",
    "# Get unique class labels and sort them\n",
    "sorted_classes = sorted(set(class_labels_int))\n",
    "\n",
    "# Create a new DataFrame filled with zeros\n",
    "transformed_df = pd.DataFrame(np.zeros((len(original_df), len(sorted_classes) + 3)), columns=['Metadata_Plate', 'Metadata_Well', 'Metadata_broad_sample'] + [str(cls) for cls in sorted_classes])\n",
    "\n",
    "# Iterate over each row in the original DataFrame\n",
    "for index, row in original_df.iterrows():\n",
    "    # Extract the classes from the fourth column\n",
    "    class_labels = [int(label) for label in row[3].split('|')]\n",
    "    # Set the values for the class labels to 1\n",
    "    transformed_df.iloc[index, 3:] = [1 if cls in class_labels else 0 for cls in sorted_classes]\n",
    "    # Set the values for the first three columns\n",
    "    transformed_df.iloc[index, 0] = int(row[0])\n",
    "    transformed_df.iloc[index, 1] = row[1]\n",
    "    transformed_df.iloc[index, 2] = row[2]\n",
    "\n",
    "# Save the transformed DataFrame to a new CSV file\n",
    "transformed_df.to_csv('transformed_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "\n",
    "csv_file_path = 'transformed_file.csv'\n",
    "\n",
    "# Path to the folder containing the images\n",
    "image_folder_path = '../preprocessing/train_bbbc_2/cell'\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "ii=0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    plate=[]\n",
    "    plate_value = str(int(float(row[\"Metadata_Plate\"])))\n",
    "    plate.append(plate_value)\n",
    "    well=[]\n",
    "    well.append(row[\"Metadata_Well\"])\n",
    "    for p in plate:\n",
    "        #print(p)\n",
    "        for w in well:\n",
    "            ii=0\n",
    "            #print(w)\n",
    "            for k in range(1):\n",
    "                for i in range(10):\n",
    "                    image_file_path = os.path.join(image_folder_path, f'{p}_{w}_s{k+1}_cell{i+1}.png')\n",
    "                    # print(image_file_path)\n",
    "                    if os.path.exists(image_file_path):\n",
    "                        reading = imread(image_file_path)\n",
    "                        ii += 1\n",
    "                        # Rename the file\n",
    "                        os.rename(image_file_path, os.path.join(image_folder_path, f'{p}_{w}_cell{ii}.png'))\n",
    "                        # print(image_file_path)\n",
    "                        # print(os.path.join(image_folder_path, f'{p}_{w}_cell{ii}.png'))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Extracts cells present in image folder and makes new csv\n",
    "'''\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file with image IDs\n",
    "csv_file_path = 'transformed_file.csv'\n",
    "\n",
    "# Path to the folder containing the images\n",
    "image_folder_path = '../preprocessing/train_bbbc_2/cell'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create an empty list to store rows for the new DataFrame\n",
    "new_rows = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    plate_value = str(int(float(row[\"Metadata_Plate\"])))\n",
    "    image_file_path = os.path.join(image_folder_path, f'{plate_value}_{row[\"Metadata_Well\"]}_cell10.png')  # Assuming images have a .jpg extension\n",
    "\n",
    "    # print(image_file_path)\n",
    "    \n",
    "    # Check if the image file exists\n",
    "    if os.path.exists(image_file_path):\n",
    "        # print(row)\n",
    "        new_rows.append(row)\n",
    "        # break\n",
    "\n",
    "# Create a new DataFrame from the list of rows\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Save the new DataFrame to a new CSV file\n",
    "new_csv_file_path = 'bbbc2_rename_10cell.csv'\n",
    "new_df.to_csv(new_csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "- Split into train, test, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Run Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run preproc_bbbc.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
